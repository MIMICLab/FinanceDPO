# Optuna‑based hyperparameter optimization config
# Run with:  python src/train.py -m +hpo

defaults:
  - override hydra/sweeper: optuna
  - dpo  # base config

hydra:
  sweeper:
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    sampler:
      _target_: optuna.samplers.TPESampler
    direction: maximize  # the pipeline logs val_sharpe; maximise it
    study_name: dpo_hpo
    storage: null  # in‑memory; set to sqlite:///study.db for persistence
    n_trials: 30
    n_jobs: 1
    params:
      # ─── data / label generation ─────────────────────────────────────
      dataset.lookback:   "choice(11, 21, 31, 41, 51, 61)"        # window lengths → feat dim 20/30/60
      dataset.lookahead:          "choice(1, 3, 5, 7, 14, 21)"      # forward return horizon (days)
      dataset.good_quantile:      "choice(0.75, 0.8)"         # top‑quartile vs quintile
      dataset.bad_quantile:       "choice(0.25, 0.2)"         # bottom‑quartile vs quintile

      # ─── model (Transformer) ─────────────────────────────────────────
      model.d_model:      "choice(32, 64, 128, 256)"
      model.n_layers:     "choice(2, 4, 8, 16)"
      model.n_heads:      "choice(4, 8, 16)"
      model.ff_dim:       "choice(128, 256, 512, 1024)"

      # ─── optimiser / training ────────────────────────────────────────
      train.lr:           "loguniform(1e-5, 1e-3)"
      train.kl_coeff:     "choice(0.0, 0.05)"         # KL off vs small regularisation
      trainer.max_epochs: "choice(10, 15, 20)"
      
# Run sweep:
#   python -m dpo_forecasting.hpo_pipeline -m +hpo
