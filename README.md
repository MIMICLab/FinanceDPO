# FinanceDPO

**Direct Preference Optimization for Decision-Driven Financial Time-Series Forecasting**

---

## âœ¨ Whatâ€™s inside?

* **Opinionated Python project layout** â€“ `src/`, `notebooks/`, `tests/`, `docs/`
* **Ready-to-run training script** â€“ [`src/train.py`](src/train.py) wired for **Hydra** + **PyTorch Lightning**
* **Conda environment spec** â€“ [`environment.yml`](environment.yml) for reproducible installs
* **CI & style tooling** â€“ `.pre-commit-config.yaml`, `.gitignore`, GitHub Actions, `pytest` placeholder
* **Developer docs** â€“ this `README.md`, [`CONTRIBUTING.md`](CONTRIBUTING.md), MIT [`LICENSE`](LICENSE)

---

## ğŸ”§ Quick start

### 1. Clone & set up
```bash
# Clone
git clone https://github.com/MIMICLab/FinanceDPO.git
cd FinanceDPO

# Create environment
conda env create -f environment.yml
conda activate dpo-finance

> **Python version**: `environment.yml` pins `python=3.11`.  
> If your base conda uses a different version, run  
> `conda env create -f environment.yml -n dpo-finance`.
```

### 2. Download raw price data (example: S&P 500)
```bash
python src/dpo_forecasting/preprocessing/download.py \
    --symbols-file data/sp500.txt \
    --start 2000-01-01
```
> `data/sp500.txt` is a plain-text list of ticker symbols, one per line (e.g. `AAPL`, `MSFT`, â€¦).

### 3. Generate preference pairs
```bash
python src/dpo_forecasting/preprocessing/make_pairs.py \
    --config src/dpo_forecasting/configs/findpo_sp500_base.yaml # or other configs
```

### 4. Train a DPO model
```bash
python src/train.py \
    --config src/dpo_forecasting/configs/findpo_sp500_base.yaml # or other configs
```

### 5. Evaluate & back-test
```bash
# 5â€‘a. Pairwise accuracy / ROC
python src/eval.py --checkpoint latest.ckpt \
                   --pairs-file data/pairs.parquet     # or --cache-file

# 5â€‘b. Quick daily long/short strategy
python src/backtest.py --checkpoint latest.ckpt \
                       --prices_dir data/raw

# 5â€‘c. Advanced backâ€‘test (position sizing, stopâ€‘loss, leverage, cost)
python src/advanced_backtest.py --checkpoint latest.ckpt \
                                --prices_dir data/raw \
                                --lookback 31 --hold 5 \
                                --score-thresh 0.5 \
                                --max-long 0.3 --max-short 0.1 \
                                --cost-bps 5
```
`advanced_backtest.py` applies positionâ€‘scaled weights, transaction costs,
and optional equity stops, giving a closer approximation to live
portfolio behaviour.  Adjust `--hold`, `--max-long`, `--cost-bps` and other
flags to reflect your trading assumptions.

### 6. Fineâ€‘tune a single symbol with a frozen referenceÂ net

You can first train a **broad, marketâ€‘wide model** (e.g. on all S&Pâ€¯500 pairs),
then fineâ€‘tune it for a specific symbol while keeping the original behaviour
as a reference via a small KLÂ penalty:

```bash
# 7â€‘a. Train a base model on the full S&PÂ 500 cache
python src/train.py --config src/configs/findpo_sp500_base.yaml

# After saving latest ckpt stored in tb_logs/version_x/checkpoints
cp tb_logs/dpo/version_x/checkpoints/xxx.ckpt findpo_sp500_base.ckpt

# 7â€‘b. Fineâ€‘tune on MAG7, pulling against the frozen base net
python src/train.py --config src/configs/findpo_mag7_base.yaml

```

The first command produces `runs/sp500_base.ckpt`.  
The second command loads that checkpoint asâ€¯`reference_net`, freezes it
internally, and trains a new policy that specializes on AAPL while being softly
regularized toward the base model.

---

## ğŸ“‚ Project layout
```
FinanceDPO/
â”œâ”€â”€ data/                  # raw & processed data (git-ignored)
â”œâ”€â”€ src/
â”‚Â Â  â””â”€â”€ dpo_forecasting/
â”‚Â Â      â”œâ”€â”€ data/          # data loaders & pair builders
â”‚Â Â      â”œâ”€â”€ models/        # model definitions & loss functions
â”‚Â Â      â””â”€â”€ configs/       # Hydra configs (dpo.yaml, hpo.yaml â€¦)
â”œâ”€â”€ tests/                 # unit tests
â”œâ”€â”€ environment.yml        # conda spec
â”œâ”€â”€ pyproject.toml         # install package via `pip install -e .`
â””â”€â”€ README.md
```

---

## ğŸ§‘â€ğŸ’» Contributing

We welcome pull requests! See [`CONTRIBUTING.md`](CONTRIBUTING.md) for the workflow.

---

## ğŸ“œ License

This project is licensed under the MIT License. See the [`LICENSE`](LICENSE) file for details.
